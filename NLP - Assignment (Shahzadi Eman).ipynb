{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85174fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\moin\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\moin\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: click in c:\\users\\moin\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\moin\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\moin\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\moin\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\moin\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\moin\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\moin\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\moin\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\moin\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9353d7b",
   "metadata": {},
   "source": [
    "# Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "693fd9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Load your dataset\n",
    "#file_path = 'sentiment_tweets3.csv'  # Change this to the path of your dataset\n",
    "data = pd.read_csv(r'C:/Users/moin/Downloads/NLP/sentiment_tweets3.csv' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f6d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\moin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\moin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\moin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69676792",
   "metadata": {},
   "source": [
    "#### Removing URLs\n",
    "This step involves removing web addresses from the text since they are usually not relevant to text analysis tasks and can be considered as noise in the data. This is typically done using regular expressions to find strings that resemble URLs and removing them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bab31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "data['no_urls'] = data['message to examine'].apply(remove_urls)  # Replace 'your_text_column'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9523a95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>message to examine</th>\n",
       "      <th>label (depression result)</th>\n",
       "      <th>processed_message</th>\n",
       "      <th>no_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>real good moment miss much</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
       "      <td>0</td>\n",
       "      <td>read manga</td>\n",
       "      <td>is reading manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
       "      <td>0</td>\n",
       "      <td>comeagainjen -</td>\n",
       "      <td>@comeagainjen  -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>0</td>\n",
       "      <td>lapcat need send 'em account tomorrow oddli n'...</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>0</td>\n",
       "      <td>add myspac myspacecom/lookthund</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                 message to examine  \\\n",
       "0    106  just had a real good moment. i missssssssss hi...   \n",
       "1    217         is reading manga  http://plurk.com/p/mzp1e   \n",
       "2    220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
       "3    288  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4    540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "\n",
       "   label (depression result)  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "                                   processed_message  \\\n",
       "0                         real good moment miss much   \n",
       "1                                         read manga   \n",
       "2                                     comeagainjen -   \n",
       "3  lapcat need send 'em account tomorrow oddli n'...   \n",
       "4                    add myspac myspacecom/lookthund   \n",
       "\n",
       "                                             no_urls  \n",
       "0  just had a real good moment. i missssssssss hi...  \n",
       "1                                 is reading manga    \n",
       "2                                 @comeagainjen  -    \n",
       "3  @lapcat Need to send 'em to my accountant tomo...  \n",
       "4      ADD ME ON MYSPACE!!!  myspace.com/LookThunder  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2306bc51",
   "metadata": {},
   "source": [
    "#### Removing Punctuation\n",
    "Punctuation marks are removed from the text because they usually don't contribute to the meaning of the text for analysis purposes (e.g., sentiment analysis, keyword extraction). This step improves the consistency of text data and helps in reducing the size of the vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a0c1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[\\.,!$()\\*\\%@]', '', text)\n",
    "\n",
    "data['no_punctuation'] = data['no_urls'].apply(remove_punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ae7fba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>message to examine</th>\n",
       "      <th>label (depression result)</th>\n",
       "      <th>processed_message</th>\n",
       "      <th>no_urls</th>\n",
       "      <th>no_punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>real good moment miss much</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>just had a real good moment i missssssssss him...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
       "      <td>0</td>\n",
       "      <td>read manga</td>\n",
       "      <td>is reading manga</td>\n",
       "      <td>is reading manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
       "      <td>0</td>\n",
       "      <td>comeagainjen -</td>\n",
       "      <td>@comeagainjen  -</td>\n",
       "      <td>comeagainjen  -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>0</td>\n",
       "      <td>lapcat need send 'em account tomorrow oddli n'...</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>lapcat Need to send 'em to my accountant tomor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>0</td>\n",
       "      <td>add myspac myspacecom/lookthund</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>ADD ME ON MYSPACE  myspacecom/LookThunder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                 message to examine  \\\n",
       "0    106  just had a real good moment. i missssssssss hi...   \n",
       "1    217         is reading manga  http://plurk.com/p/mzp1e   \n",
       "2    220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
       "3    288  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4    540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "\n",
       "   label (depression result)  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "                                   processed_message  \\\n",
       "0                         real good moment miss much   \n",
       "1                                         read manga   \n",
       "2                                     comeagainjen -   \n",
       "3  lapcat need send 'em account tomorrow oddli n'...   \n",
       "4                    add myspac myspacecom/lookthund   \n",
       "\n",
       "                                             no_urls  \\\n",
       "0  just had a real good moment. i missssssssss hi...   \n",
       "1                                 is reading manga     \n",
       "2                                 @comeagainjen  -     \n",
       "3  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "\n",
       "                                      no_punctuation  \n",
       "0  just had a real good moment i missssssssss him...  \n",
       "1                                 is reading manga    \n",
       "2                                  comeagainjen  -    \n",
       "3  lapcat Need to send 'em to my accountant tomor...  \n",
       "4          ADD ME ON MYSPACE  myspacecom/LookThunder  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2d0b1e",
   "metadata": {},
   "source": [
    "#### Lower Casing\n",
    "Converting all text data into lower case ensures that the algorithm does not treat the same words in different cases as different words (e.g., \"Hello\" vs \"hello\"). This normalization step is crucial for consistency and reducing the complexity of the text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3962db44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>message to examine</th>\n",
       "      <th>label (depression result)</th>\n",
       "      <th>processed_message</th>\n",
       "      <th>no_urls</th>\n",
       "      <th>no_punctuation</th>\n",
       "      <th>lower_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>real good moment miss much</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>just had a real good moment i missssssssss him...</td>\n",
       "      <td>just had a real good moment i missssssssss him...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
       "      <td>0</td>\n",
       "      <td>read manga</td>\n",
       "      <td>is reading manga</td>\n",
       "      <td>is reading manga</td>\n",
       "      <td>is reading manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
       "      <td>0</td>\n",
       "      <td>comeagainjen -</td>\n",
       "      <td>@comeagainjen  -</td>\n",
       "      <td>comeagainjen  -</td>\n",
       "      <td>comeagainjen  -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>0</td>\n",
       "      <td>lapcat need send 'em account tomorrow oddli n'...</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>lapcat Need to send 'em to my accountant tomor...</td>\n",
       "      <td>lapcat need to send 'em to my accountant tomor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>0</td>\n",
       "      <td>add myspac myspacecom/lookthund</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>ADD ME ON MYSPACE  myspacecom/LookThunder</td>\n",
       "      <td>add me on myspace  myspacecom/lookthunder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                 message to examine  \\\n",
       "0    106  just had a real good moment. i missssssssss hi...   \n",
       "1    217         is reading manga  http://plurk.com/p/mzp1e   \n",
       "2    220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
       "3    288  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4    540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "\n",
       "   label (depression result)  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "                                   processed_message  \\\n",
       "0                         real good moment miss much   \n",
       "1                                         read manga   \n",
       "2                                     comeagainjen -   \n",
       "3  lapcat need send 'em account tomorrow oddli n'...   \n",
       "4                    add myspac myspacecom/lookthund   \n",
       "\n",
       "                                             no_urls  \\\n",
       "0  just had a real good moment. i missssssssss hi...   \n",
       "1                                 is reading manga     \n",
       "2                                 @comeagainjen  -     \n",
       "3  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "\n",
       "                                      no_punctuation  \\\n",
       "0  just had a real good moment i missssssssss him...   \n",
       "1                                 is reading manga     \n",
       "2                                  comeagainjen  -     \n",
       "3  lapcat Need to send 'em to my accountant tomor...   \n",
       "4          ADD ME ON MYSPACE  myspacecom/LookThunder   \n",
       "\n",
       "                                          lower_case  \n",
       "0  just had a real good moment i missssssssss him...  \n",
       "1                                 is reading manga    \n",
       "2                                  comeagainjen  -    \n",
       "3  lapcat need to send 'em to my accountant tomor...  \n",
       "4          add me on myspace  myspacecom/lookthunder  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lower_case'] = data['no_punctuation'].apply(lambda x: x.lower())\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377fada0",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "Tokenization is the process of splitting text into individual terms or words. This is a fundamental step in text preprocessing as it transforms text into a format that's easier to analyze and work with, especially for tasks that require understanding the individual components of the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32eecf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\moin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "data['tokens'] = data['lower_case'].apply(tokenize_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63253f",
   "metadata": {},
   "source": [
    "#### Removing Stop Words\n",
    "Stop words (e.g., \"the\", \"a\", \"an\", \"in\") are commonly used words in a language that are usually removed in the process of text analysis because they contribute little to the overall meaning of the text. Removing them helps focus on the more meaningful words in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e695313d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\moin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "data['filtered_tokens'] = data['tokens'].apply(remove_stop_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a4ef0",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "Stemming is the process of reducing words to their base or root form. For example, \"fishing\", \"fished\", and \"fisher\" all get reduced to \"fish\". This helps in generalizing different forms of the same word to a single item and reduces the complexity of the text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b9973e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>message to examine</th>\n",
       "      <th>label (depression result)</th>\n",
       "      <th>processed_message</th>\n",
       "      <th>no_urls</th>\n",
       "      <th>no_punctuation</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>tokens</th>\n",
       "      <th>filtered_tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>real good moment miss much</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>just had a real good moment i missssssssss him...</td>\n",
       "      <td>just had a real good moment i missssssssss him...</td>\n",
       "      <td>[just, had, a, real, good, moment, i, missssss...</td>\n",
       "      <td>[real, good, moment, missssssssss, much]</td>\n",
       "      <td>[real, good, moment, missssssssss, much]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
       "      <td>0</td>\n",
       "      <td>read manga</td>\n",
       "      <td>is reading manga</td>\n",
       "      <td>is reading manga</td>\n",
       "      <td>is reading manga</td>\n",
       "      <td>[is, reading, manga]</td>\n",
       "      <td>[reading, manga]</td>\n",
       "      <td>[read, manga]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
       "      <td>0</td>\n",
       "      <td>comeagainjen -</td>\n",
       "      <td>@comeagainjen  -</td>\n",
       "      <td>comeagainjen  -</td>\n",
       "      <td>comeagainjen  -</td>\n",
       "      <td>[comeagainjen, -]</td>\n",
       "      <td>[comeagainjen, -]</td>\n",
       "      <td>[comeagainjen, -]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>0</td>\n",
       "      <td>lapcat need send 'em account tomorrow oddli n'...</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>lapcat Need to send 'em to my accountant tomor...</td>\n",
       "      <td>lapcat need to send 'em to my accountant tomor...</td>\n",
       "      <td>[lapcat, need, to, send, 'em, to, my, accounta...</td>\n",
       "      <td>[lapcat, need, send, 'em, accountant, tomorrow...</td>\n",
       "      <td>[lapcat, need, send, 'em, account, tomorrow, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>0</td>\n",
       "      <td>add myspac myspacecom/lookthund</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>ADD ME ON MYSPACE  myspacecom/LookThunder</td>\n",
       "      <td>add me on myspace  myspacecom/lookthunder</td>\n",
       "      <td>[add, me, on, myspace, myspacecom/lookthunder]</td>\n",
       "      <td>[add, myspace, myspacecom/lookthunder]</td>\n",
       "      <td>[add, myspac, myspacecom/lookthund]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                 message to examine  \\\n",
       "0    106  just had a real good moment. i missssssssss hi...   \n",
       "1    217         is reading manga  http://plurk.com/p/mzp1e   \n",
       "2    220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
       "3    288  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4    540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "\n",
       "   label (depression result)  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "                                   processed_message  \\\n",
       "0                         real good moment miss much   \n",
       "1                                         read manga   \n",
       "2                                     comeagainjen -   \n",
       "3  lapcat need send 'em account tomorrow oddli n'...   \n",
       "4                    add myspac myspacecom/lookthund   \n",
       "\n",
       "                                             no_urls  \\\n",
       "0  just had a real good moment. i missssssssss hi...   \n",
       "1                                 is reading manga     \n",
       "2                                 @comeagainjen  -     \n",
       "3  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "\n",
       "                                      no_punctuation  \\\n",
       "0  just had a real good moment i missssssssss him...   \n",
       "1                                 is reading manga     \n",
       "2                                  comeagainjen  -     \n",
       "3  lapcat Need to send 'em to my accountant tomor...   \n",
       "4          ADD ME ON MYSPACE  myspacecom/LookThunder   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  just had a real good moment i missssssssss him...   \n",
       "1                                 is reading manga     \n",
       "2                                  comeagainjen  -     \n",
       "3  lapcat need to send 'em to my accountant tomor...   \n",
       "4          add me on myspace  myspacecom/lookthunder   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [just, had, a, real, good, moment, i, missssss...   \n",
       "1                               [is, reading, manga]   \n",
       "2                                  [comeagainjen, -]   \n",
       "3  [lapcat, need, to, send, 'em, to, my, accounta...   \n",
       "4     [add, me, on, myspace, myspacecom/lookthunder]   \n",
       "\n",
       "                                     filtered_tokens  \\\n",
       "0           [real, good, moment, missssssssss, much]   \n",
       "1                                   [reading, manga]   \n",
       "2                                  [comeagainjen, -]   \n",
       "3  [lapcat, need, send, 'em, accountant, tomorrow...   \n",
       "4             [add, myspace, myspacecom/lookthunder]   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0           [real, good, moment, missssssssss, much]  \n",
       "1                                      [read, manga]  \n",
       "2                                  [comeagainjen, -]  \n",
       "3  [lapcat, need, send, 'em, account, tomorrow, o...  \n",
       "4                [add, myspac, myspacecom/lookthund]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(tokens):\n",
    "    return [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "data['stemmed_tokens'] = data['filtered_tokens'].apply(stem_words)\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc04efbb",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "Similar to stemming, lemmatization also involves reducing words to their base form, but unlike stemming, it brings context to the words. Thus, it links words with similar meaning to one word. For example, “better” is converted to its base form, “good”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99dd2d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\moin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_words(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "data['lemmatized_tokens'] = data['stemmed_tokens'].apply(lemmatize_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2accd4fb",
   "metadata": {},
   "source": [
    "#### Sentence Segmentation\n",
    "This step involves breaking text into individual sentences. It’s crucial for tasks that operate on a per-sentence basis (like summarizing) and helps in understanding the structure and flow of the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fb1d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentences(text):\n",
    "    return nltk.sent_tokenize(text)\n",
    "\n",
    "data['sentences'] = data['message to examine'].apply(segment_sentences)  # Replace 'your_text_column'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72401b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>message to examine</th>\n",
       "      <th>label (depression result)</th>\n",
       "      <th>processed_message</th>\n",
       "      <th>no_urls</th>\n",
       "      <th>no_punctuation</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>tokens</th>\n",
       "      <th>filtered_tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>real good moment miss much</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>just had a real good moment i missssssssss him...</td>\n",
       "      <td>just had a real good moment i missssssssss him...</td>\n",
       "      <td>[just, had, a, real, good, moment, i, missssss...</td>\n",
       "      <td>[real, good, moment, missssssssss, much]</td>\n",
       "      <td>[real, good, moment, missssssssss, much]</td>\n",
       "      <td>[real, good, moment, miss, much]</td>\n",
       "      <td>[just had a real good moment., i missssssssss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
       "      <td>0</td>\n",
       "      <td>read manga</td>\n",
       "      <td>is reading manga</td>\n",
       "      <td>is reading manga</td>\n",
       "      <td>is reading manga</td>\n",
       "      <td>[is, reading, manga]</td>\n",
       "      <td>[reading, manga]</td>\n",
       "      <td>[read, manga]</td>\n",
       "      <td>[read, manga]</td>\n",
       "      <td>[is reading manga  http://plurk.com/p/mzp1e]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
       "      <td>0</td>\n",
       "      <td>comeagainjen -</td>\n",
       "      <td>@comeagainjen  -</td>\n",
       "      <td>comeagainjen  -</td>\n",
       "      <td>comeagainjen  -</td>\n",
       "      <td>[comeagainjen, -]</td>\n",
       "      <td>[comeagainjen, -]</td>\n",
       "      <td>[comeagainjen, -]</td>\n",
       "      <td>[comeagainjen, -]</td>\n",
       "      <td>[@comeagainjen http://twitpic.com/2y2lx - http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>0</td>\n",
       "      <td>lapcat need send 'em account tomorrow oddli n'...</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>lapcat Need to send 'em to my accountant tomor...</td>\n",
       "      <td>lapcat need to send 'em to my accountant tomor...</td>\n",
       "      <td>[lapcat, need, to, send, 'em, to, my, accounta...</td>\n",
       "      <td>[lapcat, need, send, 'em, accountant, tomorrow...</td>\n",
       "      <td>[lapcat, need, send, 'em, account, tomorrow, o...</td>\n",
       "      <td>[lapcat, need, send, 'em, account, tomorrow, o...</td>\n",
       "      <td>[@lapcat Need to send 'em to my accountant tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>0</td>\n",
       "      <td>add myspac myspacecom/lookthund</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>ADD ME ON MYSPACE  myspacecom/LookThunder</td>\n",
       "      <td>add me on myspace  myspacecom/lookthunder</td>\n",
       "      <td>[add, me, on, myspace, myspacecom/lookthunder]</td>\n",
       "      <td>[add, myspace, myspacecom/lookthunder]</td>\n",
       "      <td>[add, myspac, myspacecom/lookthund]</td>\n",
       "      <td>[add, myspac, myspacecom/lookthund]</td>\n",
       "      <td>[ADD ME ON MYSPACE!!!, myspace.com/LookThunder]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                 message to examine  \\\n",
       "0    106  just had a real good moment. i missssssssss hi...   \n",
       "1    217         is reading manga  http://plurk.com/p/mzp1e   \n",
       "2    220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
       "3    288  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4    540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "\n",
       "   label (depression result)  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "                                   processed_message  \\\n",
       "0                         real good moment miss much   \n",
       "1                                         read manga   \n",
       "2                                     comeagainjen -   \n",
       "3  lapcat need send 'em account tomorrow oddli n'...   \n",
       "4                    add myspac myspacecom/lookthund   \n",
       "\n",
       "                                             no_urls  \\\n",
       "0  just had a real good moment. i missssssssss hi...   \n",
       "1                                 is reading manga     \n",
       "2                                 @comeagainjen  -     \n",
       "3  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "\n",
       "                                      no_punctuation  \\\n",
       "0  just had a real good moment i missssssssss him...   \n",
       "1                                 is reading manga     \n",
       "2                                  comeagainjen  -     \n",
       "3  lapcat Need to send 'em to my accountant tomor...   \n",
       "4          ADD ME ON MYSPACE  myspacecom/LookThunder   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  just had a real good moment i missssssssss him...   \n",
       "1                                 is reading manga     \n",
       "2                                  comeagainjen  -     \n",
       "3  lapcat need to send 'em to my accountant tomor...   \n",
       "4          add me on myspace  myspacecom/lookthunder   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [just, had, a, real, good, moment, i, missssss...   \n",
       "1                               [is, reading, manga]   \n",
       "2                                  [comeagainjen, -]   \n",
       "3  [lapcat, need, to, send, 'em, to, my, accounta...   \n",
       "4     [add, me, on, myspace, myspacecom/lookthunder]   \n",
       "\n",
       "                                     filtered_tokens  \\\n",
       "0           [real, good, moment, missssssssss, much]   \n",
       "1                                   [reading, manga]   \n",
       "2                                  [comeagainjen, -]   \n",
       "3  [lapcat, need, send, 'em, accountant, tomorrow...   \n",
       "4             [add, myspace, myspacecom/lookthunder]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0           [real, good, moment, missssssssss, much]   \n",
       "1                                      [read, manga]   \n",
       "2                                  [comeagainjen, -]   \n",
       "3  [lapcat, need, send, 'em, account, tomorrow, o...   \n",
       "4                [add, myspac, myspacecom/lookthund]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0                   [real, good, moment, miss, much]   \n",
       "1                                      [read, manga]   \n",
       "2                                  [comeagainjen, -]   \n",
       "3  [lapcat, need, send, 'em, account, tomorrow, o...   \n",
       "4                [add, myspac, myspacecom/lookthund]   \n",
       "\n",
       "                                           sentences  \n",
       "0  [just had a real good moment., i missssssssss ...  \n",
       "1       [is reading manga  http://plurk.com/p/mzp1e]  \n",
       "2  [@comeagainjen http://twitpic.com/2y2lx - http...  \n",
       "3  [@lapcat Need to send 'em to my accountant tom...  \n",
       "4    [ADD ME ON MYSPACE!!!, myspace.com/LookThunder]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa0e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
